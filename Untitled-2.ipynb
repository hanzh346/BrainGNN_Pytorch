{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "hang_FDG = pd.read_csv('/media/hang/EXTERNAL_US/Data/1_HANG_FDG_PET/ADNI_Second_organized/1_HANG_FDG_PET_1_30_2024.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_871964/964816.py:1: DtypeWarning: Columns (19,20,21,50,51,104,105,106) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  ADNI_merge = pd.read_csv('/media/hang/EXTERNAL_US/Data/1_HANG_FDG_PET/ADNIMERGE_30Jan2024.csv')\n"
     ]
    }
   ],
   "source": [
    "ADNI_merge = pd.read_csv('/media/hang/EXTERNAL_US/Data/1_HANG_FDG_PET/ADNIMERGE_30Jan2024.csv')\n",
    "merged_adnimerge_fdg_pet = pd.merge(hang_FDG, ADNI_merge, left_on='Subject', right_on='PTID')\n",
    "merged_adnimerge_fdg_pet = merged_adnimerge_fdg_pet[merged_adnimerge_fdg_pet['Modality']=='PET']\n",
    "merged_adnimerge_fdg_pet = merged_adnimerge_fdg_pet[merged_adnimerge_fdg_pet['Description'].str.match('Coreg, Avg, Std Img and Vox Siz, Uniform 6mm Res')]\n",
    "merged_adnimerge_fdg_pet['Acq Date'] = pd.to_datetime(merged_adnimerge_fdg_pet['Acq Date']) \n",
    "merged_adnimerge_fdg_pet.rename(columns={'Acq Date':'Acq Date Bl'}, inplace=True)\n",
    "merged_adnimerge_fdg_pet.to_csv('/media/hang/EXTERNAL_US/Data/1_HANG_FDG_PET/demographic/ADNIMERGE WITH FDG PET.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hang_FDG_all = pd.read_csv('/media/hang/EXTERNAL_US/Data/1_HANG_FDG_PET/longitudinal_AD_MCI_CN/4_TRIAL_HANG_5_10_2024.csv')\n",
    "hang_FDG_all[hang_FDG_all['Description'].str.contains('6mm')].shape\n",
    "\n",
    "hang_FDG_ab_pos = pd.read_csv('/media/hang/EXTERNAL_US/Data/1_HANG_FDG_PET/longitudinal_AD_MCI_CN/3_HANG_LONG_5_03_2024.csv')\n",
    "\n",
    "ab_pos_cases = hang_FDG_ab_pos[hang_FDG_ab_pos['Description'].str.contains('6mm')]['Subject'].drop_duplicates()\n",
    "print(len(set(ab_pos_cases)))\n",
    "\n",
    "hang_FDG_CN_ab_neg = pd.read_csv('/media/hang/EXTERNAL_US/Data/1_HANG_FDG_PET/longitudinal_CN/4_ALL_FDG_3_27_2024.csv')\n",
    "ab_neg_cases = hang_FDG_CN_ab_neg[hang_FDG_CN_ab_neg['Description'].str.contains('6mm')]['Subject'].drop_duplicates()\n",
    "print(len(set(ab_neg_cases)))\n",
    "\n",
    "\n",
    "union_set_longitudinal = set(ab_pos_cases).union(set(ab_neg_cases))\n",
    "union_set_longitudinal\n",
    "intersect_set_longitudinal = set(ab_pos_cases).intersection(set(ab_neg_cases))\n",
    "intersect_set_longitudinal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hang_FDG_ab_pos_MRI = hang_FDG_ab_pos[hang_FDG_ab_pos['Description'].str.contains('MT1')]\n",
    "print(pd.DataFrame(hang_FDG_ab_pos_MRI).sort_values(by='Subject').drop_duplicates(subset='Subject',keep='first'))\n",
    "hang_FDG_ab_pos_PET = hang_FDG_ab_pos[hang_FDG_ab_pos['Description'].str.contains('6mm')]\n",
    "#print(pd.DataFrame(hang_FDG_ab_pos_PET).sort_values(by='Subject').drop_duplicates(subset='Subject',keep='first'))\n",
    "\n",
    "hang_FDG_ab_pos_PET['Acq Date'] = pd.to_datetime(hang_FDG_ab_pos_PET['Acq Date'])\n",
    "hang_FDG_ab_pos_MRI['Acq Date'] = pd.to_datetime(hang_FDG_ab_pos_MRI['Acq Date'])\n",
    "print('overlaped_ab+ PET and MRI',len(set(hang_FDG_ab_pos_PET['Subject']) & set(hang_FDG_ab_pos_MRI['Subject'])))\n",
    "\n",
    "hang_FDG_ab_neg_MRI = hang_FDG_CN_ab_neg[hang_FDG_CN_ab_neg['Description'].str.contains('MT1')]\n",
    "hang_FDG_ab_neg_PET = hang_FDG_CN_ab_neg[hang_FDG_CN_ab_neg['Description'].str.contains('6mm')]\n",
    "\n",
    "hang_FDG_ab_neg_PET['Acq Date'] = pd.to_datetime(hang_FDG_ab_neg_PET['Acq Date'])\n",
    "hang_FDG_ab_neg_MRI['Acq Date'] = pd.to_datetime(hang_FDG_ab_neg_MRI['Acq Date'])\n",
    "print('overlaped_ab- PET and MRI',len(set(hang_FDG_ab_neg_PET['Subject']) & set(hang_FDG_ab_neg_MRI['Subject'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialize an empty list to store results\n",
    "smallest_gaps = []\n",
    "\n",
    "# Process each subject's data separately\n",
    "for subject in hang_FDG_ab_pos_PET['Subject'].unique():\n",
    "    # Get all PET and MRI records for this subject\n",
    "    pet_subject = hang_FDG_ab_pos_PET[hang_FDG_ab_pos_PET['Subject'] == subject]\n",
    "    mri_subject = hang_FDG_ab_pos_MRI[hang_FDG_ab_pos_MRI['Subject'] == subject]\n",
    "   \n",
    "\n",
    "    # Initialize the minimum gap as a large value\n",
    "    min_gap = pd.Timedelta(days=9999)\n",
    "\n",
    "    # Compare each PET date with every MRI date\n",
    "    if mri_subject.empty:\n",
    "        print('No MRI subjects for {}'.format(subject))\n",
    "    for pet_date in pet_subject['Acq Date']:\n",
    "        for mri_date in mri_subject['Acq Date']:\n",
    "            # Calculate the absolute difference\n",
    "            gap = abs(pet_date - mri_date)\n",
    "            # Update the minimum gap if the current one is smaller\n",
    "            if gap < min_gap:\n",
    "                min_gap = gap\n",
    "                best_pair = (pet_date, mri_date)\n",
    "\n",
    "    # If there is a valid match, add the smallest gap information\n",
    "    if min_gap != pd.Timedelta(days=9999):\n",
    "        if min_gap > pd.Timedelta(days=365):\n",
    "            continue\n",
    "        smallest_gaps.append({\n",
    "            'Subject': subject,\n",
    "            'PET_Date': best_pair[0],\n",
    "            'MRI_Date': best_pair[1],\n",
    "            'Smallest_Gap': min_gap\n",
    "        })\n",
    "\n",
    "# Convert the results to a DataFrame\n",
    "smallest_gaps_df = pd.DataFrame(smallest_gaps).drop_duplicates()\n",
    "#smallest_gaps_df.to_csv('/media/hang/EXTERNAL_US/Data/1_HANG_FDG_PET/longitudinal_CN/negative_longitudinal_PET_MRI_pair.csv')\n",
    "smallest_gaps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "\n",
    "class_pairs = [['CN', 'SMC'], ['CN', 'SMC'],['EMCI', 'LMCI'],'AD']\n",
    "UCBERKLEY_PET = pd.read_excel('/home/hang/GU/Project/AD_classification_synthesis/data/ADNI/UCBERKELEYAV45_01_14_21.xlsx')\n",
    "dataTable = pd.read_csv('/home/hang/GitHub/BrainGNN_Pytorch/data/filtered_selectedDataUnique_merged_ADNI.csv')\n",
    "\n",
    "# Filter UCBERKLEY_PET for baseline rows if there is a specific column indicating baseline (assuming 'VISCODE' column here)\n",
    "UCBERKLEY_PET_bl = UCBERKLEY_PET[UCBERKLEY_PET['VISCODE2'] == 'bl']\n",
    "\n",
    "# Perform an inner join on the Subject column\n",
    "merged_data = pd.merge(dataTable, UCBERKLEY_PET_bl, left_on='RID', right_on='RID', how='inner').drop_duplicates(subset='Subject',keep='last')\n",
    "\n",
    "merged_data['binary_labels_cross_section'] = merged_data.apply(lambda row:\n",
    "            0 if row['DX_bl'] in class_pairs[0] and row['SUMMARYSUVR_WHOLECEREBNORM'] < 1.11 else\n",
    "            1 if row['DX_bl'] in class_pairs[1] and row['SUMMARYSUVR_WHOLECEREBNORM'] >= 1.11 else\n",
    "            2 if row['DX_bl'] in class_pairs[2] and row['SUMMARYSUVR_WHOLECEREBNORM'] >= 1.11 else\n",
    "            3 if row['DX_bl'] in class_pairs[3] and row['SUMMARYSUVR_WHOLECEREBNORM'] >= 1.11 else np.nan, axis=1)\n",
    "\n",
    "merged_data['binary_labels_longitude'] = merged_data.apply(lambda row:\n",
    "            0 if row['DX_bl'] in class_pairs[0] and row['SUMMARYSUVR_COMPOSITE_REFNORM'] < 0.79 else\n",
    "            1 if row['DX_bl'] in class_pairs[1] and row['SUMMARYSUVR_COMPOSITE_REFNORM'] >= 0.79 else\n",
    "            2 if row['DX_bl'] in class_pairs[2] and row['SUMMARYSUVR_COMPOSITE_REFNORM'] >= 0.79 else\n",
    "            3 if row['DX_bl'] in class_pairs[3] and row['SUMMARYSUVR_COMPOSITE_REFNORM'] >= 0.79 else np.nan, axis=1)\n",
    "\n",
    "filtered_data = merged_data.dropna(subset=['binary_labels_cross_section'])\n",
    "# filtered_data = filtered_data.dropna(subset=['binary_labels_longitude'])\n",
    "filtered_data= filtered_data.drop_duplicates(subset='Subject', keep='last')\n",
    "merged_data.to_csv('merged_filtered_selected_data_ADNI_merge_with_UCBERKELEYAV45_01_14_21.csv')\n",
    "filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import timeit\n",
    "import networkx as nx\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import networkx as nx\n",
    "from scipy.io import loadmat\n",
    "from torch_geometric.data import Data,  Batch\n",
    "from torch_geometric.utils import  remove_self_loops\n",
    "import multiprocessing\n",
    "from torch_sparse import coalesce\n",
    "from functools import partial\n",
    "def extract_features(file_path, field_name='scaledMahalDistMatrix'):\n",
    "    \"\"\"\n",
    "    Placeholder function for extracting features from a .mat file.\n",
    "    Implement according to your specific requirements.\n",
    "    \"\"\"\n",
    "    mat = loadmat(file_path)\n",
    "    return mat[field_name]\n",
    "\n",
    "def apply_threshold(matrix, percentile):\n",
    "    # Flatten the matrix and sort it\n",
    "    sorted_matrix = np.sort(matrix)\n",
    "    # Calculate the index for the desired percentile\n",
    "    threshold_index = round(len(sorted_matrix) * (100 - percentile) / 100)  # Adjust for zero indexing\n",
    "\n",
    "    # Get the threshold value using the sorted matrix\n",
    "    threshold_value = sorted_matrix[threshold_index]\n",
    "    # Apply thresholding\n",
    "    thresholded_matrix = np.where(matrix > threshold_value, matrix, 0)\n",
    "    return thresholded_matrix\n",
    "\n",
    "\n",
    "def process_subject(subject_id, binary_label, mat_files_dir, percentile, connectome):\n",
    "    \"\"\"\n",
    "    Process a single subject's graph data for classification, including binary label.\n",
    "    \"\"\"\n",
    "    mat_file_path = os.path.join(mat_files_dir, f\"{subject_id}_{connectome}.mat\")\n",
    "    par_corr_file_path = os.path.join(mat_files_dir, f\"{subject_id}_partial_correlation_KDE.mat\")\n",
    "\n",
    "    # Check if files exist\n",
    "    if not os.path.exists(mat_file_path) or not os.path.exists(par_corr_file_path):\n",
    "        print(f\"Files for subject {subject_id} are missing. Paths: {mat_file_path}, {par_corr_file_path}\")\n",
    "        return None\n",
    "    \n",
    "    # Determine the field name based on connectome type\n",
    "    field_name = {\n",
    "        'ScaledMahalanobisDistanceMatrix': 'scaledMahalDistMatrix',\n",
    "        'Z_scoring': 'zScoreConnectivityMatrix',\n",
    "        'K_correlation': 'correlationMatrix',\n",
    "        'JSdivMatrix': 'K_JS_Divergence'\n",
    "    }.get(connectome, None)\n",
    "    \n",
    "\n",
    "    print(f\"Processing subject {subject_id} with connectome: {connectome}\")\n",
    "\n",
    "    # Extract features\n",
    "    node_features = apply_threshold(extract_features(mat_file_path, field_name=field_name), percentile=percentile)\n",
    "    edge_features = apply_threshold(extract_features(par_corr_file_path, field_name='partial_corr'), percentile=percentile)\n",
    "\n",
    "\n",
    "    # Construct graph\n",
    "    num_nodes = node_features.shape[0]\n",
    "    G = nx.from_numpy_array(edge_features)\n",
    "    A = nx.to_scipy_sparse_array(G, format='coo')\n",
    "    adj = A.tocoo()\n",
    "\n",
    "    # Create edge attributes\n",
    "    edge_att = np.zeros(len(adj.row))\n",
    "    for i in range(len(adj.row)):\n",
    "        edge_att[i] = node_features[adj.row[i], adj.col[i]]\n",
    "\n",
    "    edge_index = np.stack([A.row, A.col])\n",
    "    edge_index, edge_att = remove_self_loops(torch.from_numpy(edge_index), torch.from_numpy(edge_att))\n",
    "    edge_index = edge_index.long()\n",
    "    edge_index, edge_att = coalesce(edge_index, edge_att, num_nodes, num_nodes)\n",
    "    pos = torch.eye(num_nodes)  # Using an identity matrix for positional data\n",
    "\n",
    "    return Data(x=torch.tensor(node_features, dtype=torch.float),\n",
    "                edge_index=edge_index,\n",
    "                edge_attr=edge_att,\n",
    "                y=torch.tensor([binary_label], dtype=torch.long),\n",
    "                pos=pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# List to store processed data\n",
    "all_data = []\n",
    "\n",
    "# Directory containing the .mat files\n",
    "mat_files_dir = \"/media/hang/EXTERNAL_US/Data/1_HANG_FDG_PET/ADNI_Second_organized/KDE_Results_corrected_by_age_sec_education/\"\n",
    "\n",
    "# Path to the raw data\n",
    "data_list_included = glob.glob('/media/hang/EXTERNAL_US/Data/1_HANG_FDG_PET/ADNI_Second_organized/KDE_Results/raw/*meanSUVR.mat')\n",
    "\n",
    "# Percentile parameter\n",
    "percentile = 10\n",
    "\n",
    "# Extract subject IDs from file names\n",
    "subject_ids_included = [filename.split('/')[-1].split('_meanSUVR')[0] for filename in data_list_included]\n",
    "\n",
    "# Assuming ADNI_merge and UCBERKLEY_PET are already loaded DataFrames\n",
    "# Example class_pairs definition\n",
    "class_pairs = [[\"CN\", \"SMC\"], ['MCI', 'EMCI', 'LMCI'], [\"Dementia\"]]\n",
    "connectome = 'Z_scoring'\n",
    "\n",
    "for id in subject_ids_included:\n",
    "    # Get the diagnosis values sorted by exam date for the subject\n",
    "    diagnosis_values = ADNI_merge[ADNI_merge['PTID'] == id].sort_values('EXAMDATE')['DX'].dropna().values\n",
    "    \n",
    "    # Check if there is more than one unique diagnosis\n",
    "    if len(set(diagnosis_values)) > 1:\n",
    "        continue\n",
    "\n",
    "    # Extract RID from the subject ID\n",
    "    rid = id.split('_')[-1]\n",
    "    print(f\"Extracted RID: {rid}\")\n",
    "\n",
    "    # Check the SUVR values for the extracted RID\n",
    "    suvr_values = UCBERKLEY_PET[UCBERKLEY_PET['RID'].astype(str) == rid]['SUMMARYSUVR_COMPOSITE_REFNORM']\n",
    "    \n",
    "    # Skip if SUVR values are empty or have mixed values for threshold\n",
    "    if suvr_values.empty or len(set(suvr_values > 0.79)) > 1:\n",
    "        continue\n",
    "\n",
    "    # Skip if there are fewer than 2 diagnosis values or SUVR values\n",
    "    if len(diagnosis_values) < 2 or len(suvr_values) < 2:\n",
    "        continue\n",
    "\n",
    "    # Determine the diagnosis and amyloid-beta status\n",
    "    diagnosis = diagnosis_values[0]\n",
    "    ab = (suvr_values > 0.79).astype(int).values[0]\n",
    "\n",
    "    # Set binary_label based on conditions\n",
    "    binary_label = np.nan\n",
    "    if diagnosis in class_pairs[0]:\n",
    "        binary_label = 0 if ab == 0 else 1\n",
    "    elif diagnosis in class_pairs[1] and ab == 1:\n",
    "        binary_label = 2\n",
    "    elif diagnosis in class_pairs[2] and ab == 1:\n",
    "        binary_label = 3\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    # Process the subject data\n",
    "    data = process_subject(id, float(binary_label), mat_files_dir, percentile=percentile, connectome=connectome)\n",
    "    \n",
    "    # Append the processed data if not None\n",
    "    if data is not None:\n",
    "        all_data.append(data)\n",
    "\n",
    "\n",
    "# Print the number of processed data entries\n",
    "print(f\"Total processed data entries: {len(all_data)}\")\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to sets for intersection\n",
    "data_list_included = glob.glob('/media/hang/EXTERNAL_US/Data/1_HANG_FDG_PET/ADNI_Second_organized/KDE_Results/raw/*meanSUVR.mat')\n",
    "subject_ids_included = [filename.split('/')[-1].split('_meanSUVR')[0] for filename in data_list_included]\n",
    "set_subject_ids_included = set(subject_ids_included)\n",
    "set_filtered_subjects = set(merged_data['Subject'])\n",
    "\n",
    "\n",
    "\n",
    "# Find intersection\n",
    "intersection_subjects_bl = set_subject_ids_included.intersection(set_filtered_subjects)\n",
    "analized_data_included_bl = merged_data[merged_data['Subject'].isin(intersection_subjects_bl)]\n",
    "\n",
    "# Print intersection result\n",
    "print(f\"Number of intersecting subjects: {len(analized_data_included_bl)}\")\n",
    "\n",
    "\n",
    "print(analized_data_included_bl.value_counts(subset='binary_labels_cross_section'))\n",
    "print(analized_data_included_bl.value_counts(subset='binary_labels_longitude'))\n",
    "union_set_longitudinal = list(union_set_longitudinal)\n",
    "#filtered_data_cross_sectional_bl_longitudinal = union_set_longitudinal[union_set_longitudinal in (analized_data_included_bl['Subject'])]\n",
    "#list(set(analized_data_included_bl['Subject']) & set(union_set_longitudinal))\n",
    "## bl subjects count\n",
    "#analized_data_included_bl[analized_data_included_bl['binary_labels_cross_section']==0]['Subject']\n",
    "analized_data_included_bl\n",
    "164+136+103+63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subjects_not_in_filtered =  set_subject_ids_included  - set_filtered_subjects\n",
    "print(\"Subjects in set_subject_ids_included but not in set_filtered_subjects:\")\n",
    "print(len(subjects_not_in_filtered))\n",
    "subjects_not_in_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import csv\n",
    "# Filter and get the list of subjects where binary_labels is 0\n",
    "subjects_list_CN_neg = analized_data_included_bl[analized_data_included_bl['binary_labels_cross_section'] == 0]['Subject']\n",
    "subjects_list_CN_pos = analized_data_included_bl[analized_data_included_bl['binary_labels_cross_section'] == 1]['Subject']\n",
    "subjects_list_MCI_pos = analized_data_included_bl[analized_data_included_bl['binary_labels_cross_section'] == 2]['Subject']\n",
    "subjects_list_AD_pos = analized_data_included_bl[analized_data_included_bl['binary_labels_cross_section'] == 3]['Subject']\n",
    "\n",
    "# Convert the series to a list of strings\n",
    "subjects_str_list_CN_neg = [str(subject) + ',' for subject in subjects_list_CN_neg]\n",
    "subjects_str_list_CN_pos = [str(subject) + ',' for subject in subjects_list_CN_pos]\n",
    "subjects_str_list_MCI_pos = [str(subject) + ',' for subject in subjects_list_MCI_pos]\n",
    "subjects_str_list_AD_pos = [str(subject) + ',' for subject in subjects_list_AD_pos]\n",
    "\n",
    "# Function to save subjects' lists to CSV files, each subject on a new line\n",
    "def save_subjects_to_csv(filename, header, subjects_list):\n",
    "    with open(filename, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([header])  # Write the header\n",
    "        for subject in subjects_list:\n",
    "            writer.writerow([subject])  # Write each subject in a new line\n",
    "\n",
    "# Save each list of subjects to separate CSV files\n",
    "save_subjects_to_csv('/media/hang/EXTERNAL_US/Data/1_HANG_FDG_PET/longitudinal_AD_MCI_CN/longitudinalthres1.11_subjects_cn_neg.csv',\n",
    "                     'CN_neg', subjects_str_list_CN_neg)\n",
    "\n",
    "save_subjects_to_csv('/media/hang/EXTERNAL_US/Data/1_HANG_FDG_PET/longitudinal_AD_MCI_CN/longitudinalthres1.11_subjects_cn_pos.csv',\n",
    "                     'CN_Pos', subjects_str_list_CN_pos)\n",
    "\n",
    "save_subjects_to_csv('/media/hang/EXTERNAL_US/Data/1_HANG_FDG_PET/longitudinal_AD_MCI_CN/longitudinalthres1.11_subjects_mci_pos.csv',\n",
    "                     'MCI_Pos', subjects_str_list_MCI_pos)\n",
    "\n",
    "save_subjects_to_csv('/media/hang/EXTERNAL_US/Data/1_HANG_FDG_PET/longitudinal_AD_MCI_CN/longitudinalthres1.11_subjects_ad_pos.csv',\n",
    "                     'AD_Pos', subjects_str_list_AD_pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_pos = list(subjects_str_list_CN_pos + subjects_str_list_MCI_pos + subjects_str_list_AD_pos)\n",
    "print(len(set(subjects_str_list_CN_neg)))\n",
    "print('ab+ overlapped cases',len(set(subject_pos) & set(ab_pos_cases)))# see the overlap of bl with longitudinal downloaded\n",
    "\n",
    "subject_neg = subjects_str_list_CN_neg\n",
    "print(set(subject_neg).intersection(set(subject_pos)))\n",
    "print('ab- overlapped cases',len(set(subject_neg) & set(ab_neg_cases)))\n",
    "print(len(set(hang_FDG_ab_pos['Subject'])))\n",
    "print(len(set(subject_pos).intersection(hang_FDG_ab_pos['Subject'])))\n",
    "print(len(set(subject_neg).intersection(hang_FDG_CN_ab_neg['Subject'])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_dict = {\n",
    "    \"Precentral_L\": 1,\n",
    "    \"Precentral_R\": 2,\n",
    "    \"Frontal_Sup_2_L\": 3,\n",
    "    \"Frontal_Sup_2_R\": 4,\n",
    "    \"Frontal_Mid_2_L\": 5,\n",
    "    \"Frontal_Mid_2_R\": 6,\n",
    "    \"Frontal_Inf_Oper_L\": 7,\n",
    "    \"Frontal_Inf_Oper_R\": 8,\n",
    "    \"Frontal_Inf_Tri_L\": 9,\n",
    "    \"Frontal_Inf_Tri_R\": 10,\n",
    "    \"Frontal_Inf_Orb_2_L\": 11,\n",
    "    \"Frontal_Inf_Orb_2_R\": 12,\n",
    "    \"Rolandic_Oper_L\": 13,\n",
    "    \"Rolandic_Oper_R\": 14,\n",
    "    \"Supp_Motor_Area_L\": 15,\n",
    "    \"Supp_Motor_Area_R\": 16,\n",
    "    \"Olfactory_L\": 17,\n",
    "    \"Olfactory_R\": 18,\n",
    "    \"Frontal_Sup_Medial_L\": 19,\n",
    "    \"Frontal_Sup_Medial_R\": 20,\n",
    "    \"Frontal_Med_Orb_L\": 21,\n",
    "    \"Frontal_Med_Orb_R\": 22,\n",
    "    \"Rectus_L\": 23,\n",
    "    \"Rectus_R\": 24,\n",
    "    \"OFCmed_L\": 25,\n",
    "    \"OFCmed_R\": 26,\n",
    "    \"OFCant_L\": 27,\n",
    "    \"OFCant_R\": 28,\n",
    "    \"OFCpost_L\": 29,\n",
    "    \"OFCpost_R\": 30,\n",
    "    \"OFClat_L\": 31,\n",
    "    \"OFClat_R\": 32,\n",
    "    \"Insula_L\": 33,\n",
    "    \"Insula_R\": 34,\n",
    "    \"Cingulate_Ant_L\": 35,\n",
    "    \"Cingulate_Ant_R\": 36,\n",
    "    \"Cingulate_Mid_L\": 37,\n",
    "    \"Cingulate_Mid_R\": 38,\n",
    "    \"Cingulate_Post_L\": 39,\n",
    "    \"Cingulate_Post_R\": 40,\n",
    "    \"Hippocampus_L\": 41,\n",
    "    \"Hippocampus_R\": 42,\n",
    "    \"ParaHippocampal_L\": 43,\n",
    "    \"ParaHippocampal_R\": 44,\n",
    "    \"Amygdala_L\": 45,\n",
    "    \"Amygdala_R\": 46,\n",
    "    \"Calcarine_L\": 47,\n",
    "    \"Calcarine_R\": 48,\n",
    "    \"Cuneus_L\": 49,\n",
    "    \"Cuneus_R\": 50,\n",
    "    \"Lingual_L\": 51,\n",
    "    \"Lingual_R\": 52,\n",
    "    \"Occipital_Sup_L\": 53,\n",
    "    \"Occipital_Sup_R\": 54,\n",
    "    \"Occipital_Mid_L\": 55,\n",
    "    \"Occipital_Mid_R\": 56,\n",
    "    \"Occipital_Inf_L\": 57,\n",
    "    \"Occipital_Inf_R\": 58,\n",
    "    \"Fusiform_L\": 59,\n",
    "    \"Fusiform_R\": 60,\n",
    "    \"Postcentral_L\": 61,\n",
    "    \"Postcentral_R\": 62,\n",
    "    \"Parietal_Sup_L\": 63,\n",
    "    \"Parietal_Sup_R\": 64,\n",
    "    \"Parietal_Inf_L\": 65,\n",
    "    \"Parietal_Inf_R\": 66,\n",
    "    \"SupraMarginal_L\": 67,\n",
    "    \"SupraMarginal_R\": 68,\n",
    "    \"Angular_L\": 69,\n",
    "    \"Angular_R\": 70,\n",
    "    \"Precuneus_L\": 71,\n",
    "    \"Precuneus_R\": 72,\n",
    "    \"Paracentral_Lobule_L\": 73,\n",
    "    \"Paracentral_Lobule_R\": 74,\n",
    "    \"Caudate_L\": 75,\n",
    "    \"Caudate_R\": 76,\n",
    "    \"Putamen_L\": 77,\n",
    "    \"Putamen_R\": 78,\n",
    "    \"Pallidum_L\": 79,\n",
    "    \"Pallidum_R\": 80,\n",
    "    \"Thalamus_L\": 81,\n",
    "    \"Thalamus_R\": 82,\n",
    "    \"Heschl_L\": 83,\n",
    "    \"Heschl_R\": 84,\n",
    "    \"Temporal_Sup_L\": 85,\n",
    "    \"Temporal_Sup_R\": 86,\n",
    "    \"Temporal_Pole_Sup_L\": 87,\n",
    "    \"Temporal_Pole_Sup_R\": 88,\n",
    "    \"Temporal_Mid_L\": 89,\n",
    "    \"Temporal_Mid_R\": 90,\n",
    "    \"Temporal_Pole_Mid_L\": 91,\n",
    "    \"Temporal_Pole_Mid_R\": 92,\n",
    "    \"Temporal_Inf_L\": 93,\n",
    "    \"Temporal_Inf_R\": 94,\n",
    "    \"Cerebelum_Crus1_L\": 95,\n",
    "    \"Cerebelum_Crus1_R\": 96,\n",
    "    \"Cerebelum_Crus2_L\": 97,\n",
    "    \"Cerebelum_Crus2_R\": 98,\n",
    "    \"Cerebelum_3_L\": 99,\n",
    "    \"Cerebelum_3_R\": 100,\n",
    "    \"Cerebelum_4_5_L\": 101,\n",
    "    \"Cerebelum_4_5_R\": 102,\n",
    "    \"Cerebelum_6_L\": 103,\n",
    "    \"Cerebelum_6_R\": 104,\n",
    "    \"Cerebelum_7b_L\": 105,\n",
    "    \"Cerebelum_7b_R\": 106,\n",
    "    \"Cerebelum_8_L\": 107,\n",
    "    \"Cerebelum_8_R\": 108,\n",
    "    \"Cerebelum_9_L\": 109,\n",
    "    \"Cerebelum_9_R\": 110,\n",
    "    \"Cerebelum_10_L\": 111,\n",
    "    \"Cerebelum_10_R\": 112,\n",
    "    \"Vermis_1_2\": 113,\n",
    "    \"Vermis_3\": 114,\n",
    "    \"Vermis_4_5\": 115,\n",
    "    \"Vermis_6\": 116,\n",
    "    \"Vermis_7\": 117,\n",
    "    \"Vermis_8\": 118,\n",
    "    \"Vermis_9\": 119,\n",
    "    \"Vermis_10\": 120\n",
    "}\n",
    "\n",
    "print(regions_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "# Define the variables\n",
    "date_time = '2024-06-03_11-07-03'\n",
    "z_scoring = 'ScaledMahalanobisDistanceMatrix'\n",
    "percentile = 20\n",
    "class_pair1 = ['CN', 'SMC']\n",
    "class_pair2 = ['MCI', 'EMCI', 'LMCI']\n",
    "# ['CN', 'SMC']#['MCI', 'EMCI', 'LMCI']#'Dementia'\n",
    "\n",
    "# Construct class pair strings with single quotes\n",
    "class_pair1_str = ', '.join([f\"'{c}'\" for c in class_pair1])\n",
    "\n",
    "class_pair2_str = ', '.join([f\"'{c}'\" for c in class_pair2])\n",
    "# Construct the file path\n",
    "file_path = f\"/home/hang/GitHub/BrainGNN_Pytorch/results/{date_time}/{z_scoring}/{percentile}/[{class_pair1_str}]_vs_{class_pair2}/results/interesting_indices.json\"\n",
    "\n",
    "# Open the file\n",
    "with open(file_path, 'r') as f:\n",
    "    indices = json.load(f)\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "# Assuming 'indices' is a dictionary loaded from the JSON file\n",
    "\n",
    "community_clustering = {0: [], 1: [], 2: [], 3: []}\n",
    "node_number_past = -1\n",
    "# Iterate through each fold and its associated nodes\n",
    "for fold, nodes in indices.items():\n",
    "    fold = ast.literal_eval(fold)  # Convert the fold string to an actual object (e.g., tuple)\n",
    "    \n",
    "    # Iterate through each batch in the list of nodes\n",
    "    for batch in range(len(nodes)):\n",
    "        # Convert the string representation of the lists to actual lists\n",
    "        community_list = ast.literal_eval(nodes[batch][0])\n",
    "        print(community_list)  # Debugging output, can be removed in production\n",
    "        \n",
    "        node_list = ast.literal_eval(nodes[batch][1])\n",
    "        print(node_list)  # Debugging output, can be removed in production\n",
    "        \n",
    "        # Convert the community list to a numpy array of integers\n",
    "        community = np.array(community_list, dtype=int)\n",
    "        \n",
    "        # Create iterators for communities and nodes\n",
    "        community_iter = iter(community)\n",
    "        community_number = next(community_iter, None)  # Start with the first community number\n",
    "\n",
    "        node_iter = iter(node_list)\n",
    "        node_number = next(node_iter, None)  # Start with the first node number\n",
    "        \n",
    "        # Iterate through the communities and nodes and append the nodes to their respective communities\n",
    "        while community_number is not None and node_number is not None:\n",
    "            community_clustering[community_number].append(node_number)\n",
    "            community_number = next(community_iter, None)\n",
    "            node_number = next(node_iter, None)\n",
    "\n",
    "    \n",
    "for keys, values in community_clustering.items():\n",
    "    # Replace the list of values with a unique set of values\n",
    "    community_clustering[keys] = np.unique(values).tolist()  # Convert to list if necessary\n",
    "\n",
    "\n",
    "\n",
    "# Reverse the regions_dict to map indices to region names\n",
    "index_to_region = {v-1: k for k, v in regions_dict.items()}\n",
    "\n",
    "# Create a new dictionary with region names instead of numeric indices\n",
    "community_clustering_with_names = []\n",
    "for community_number, nodes in community_clustering.items():\n",
    "\n",
    "    region_name = [index_to_region.get(node, f\"Unknown_{community_number}\") for node in nodes]\n",
    "    community_clustering_with_names.append(region_name)\n",
    "\n",
    "print(community_clustering_with_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn import plotting, image\n",
    "from nilearn.image import math_img, resample_to_img,new_img_like\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load the AAL2 atlas from the local path\n",
    "path_to_aal2 = '/home/hang/dsi-studio/atlas/ICBM152_adult/AAL2.nii.gz'\n",
    "aal_atlas = image.load_img(path_to_aal2)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn import plotting\n",
    "from nilearn.image import new_img_like, math_img\n",
    "import matplotlib as mpl\n",
    "# Provided data for constructing regions_dict\n",
    "regions_data = \"\"\"\n",
    "Precentral_L 1 2001\n",
    "Precentral_R 2 2002\n",
    "Frontal_Sup_2_L 3 2101\n",
    "Frontal_Sup_2_R 4 2102\n",
    "Frontal_Mid_2_L 5 2201\n",
    "Frontal_Mid_2_R 6 2202\n",
    "Frontal_Inf_Oper_L 7 2301\n",
    "Frontal_Inf_Oper_R 8 2302\n",
    "Frontal_Inf_Tri_L 9 2311\n",
    "Frontal_Inf_Tri_R 10 2312\n",
    "Frontal_Inf_Orb_2_L 11 2321\n",
    "Frontal_Inf_Orb_2_R 12 2322\n",
    "Rolandic_Oper_L 13 2331\n",
    "Rolandic_Oper_R 14 2332\n",
    "Supp_Motor_Area_L 15 2401\n",
    "Supp_Motor_Area_R 16 2402\n",
    "Olfactory_L 17 2501\n",
    "Olfactory_R 18 2502\n",
    "Frontal_Sup_Medial_L 19 2601\n",
    "Frontal_Sup_Medial_R 20 2602\n",
    "Frontal_Med_Orb_L 21 2611\n",
    "Frontal_Med_Orb_R 22 2612\n",
    "Rectus_L 23 2701\n",
    "Rectus_R 24 2702\n",
    "OFCmed_L 25 2801\n",
    "OFCmed_R 26 2802\n",
    "OFCant_L 27 2811\n",
    "OFCant_R 28 2812\n",
    "OFCpost_L 29 2821\n",
    "OFCpost_R 30 2822\n",
    "OFClat_L 31 2831\n",
    "OFClat_R 32 2832\n",
    "Insula_L 33 3001\n",
    "Insula_R 34 3002\n",
    "Cingulate_Ant_L 35 4001\n",
    "Cingulate_Ant_R 36 4002\n",
    "Cingulate_Mid_L 37 4011\n",
    "Cingulate_Mid_R 38 4012\n",
    "Cingulate_Post_L 39 4021\n",
    "Cingulate_Post_R 40 4022\n",
    "Hippocampus_L 41 4101\n",
    "Hippocampus_R 42 4102\n",
    "ParaHippocampal_L 43 4111\n",
    "ParaHippocampal_R 44 4112\n",
    "Amygdala_L 45 4201\n",
    "Amygdala_R 46 4202\n",
    "Calcarine_L 47 5001\n",
    "Calcarine_R 48 5002\n",
    "Cuneus_L 49 5011\n",
    "Cuneus_R 50 5012\n",
    "Lingual_L 51 5021\n",
    "Lingual_R 52 5022\n",
    "Occipital_Sup_L 53 5101\n",
    "Occipital_Sup_R 54 5102\n",
    "Occipital_Mid_L 55 5201\n",
    "Occipital_Mid_R 56 5202\n",
    "Occipital_Inf_L 57 5301\n",
    "Occipital_Inf_R 58 5302\n",
    "Fusiform_L 59 5401\n",
    "Fusiform_R 60 5402\n",
    "Postcentral_L 61 6001\n",
    "Postcentral_R 62 6002\n",
    "Parietal_Sup_L 63 6101\n",
    "Parietal_Sup_R 64 6102\n",
    "Parietal_Inf_L 65 6201\n",
    "Parietal_Inf_R 66 6202\n",
    "SupraMarginal_L 67 6211\n",
    "SupraMarginal_R 68 6212\n",
    "Angular_L 69 6221\n",
    "Angular_R 70 6222\n",
    "Precuneus_L 71 6301\n",
    "Precuneus_R 72 6302\n",
    "Paracentral_Lobule_L 73 6401\n",
    "Paracentral_Lobule_R 74 6402\n",
    "Caudate_L 75 7001\n",
    "Caudate_R 76 7002\n",
    "Putamen_L 77 7011\n",
    "Putamen_R 78 7012\n",
    "Pallidum_L 79 7021\n",
    "Pallidum_R 80 7022\n",
    "Thalamus_L 81 7101\n",
    "Thalamus_R 82 7102\n",
    "Heschl_L 83 8101\n",
    "Heschl_R 84 8102\n",
    "Temporal_Sup_L 85 8111\n",
    "Temporal_Sup_R 86 8112\n",
    "Temporal_Pole_Sup_L 87 8121\n",
    "Temporal_Pole_Sup_R 88 8122\n",
    "Temporal_Mid_L 89 8201\n",
    "Temporal_Mid_R 90 8202\n",
    "Temporal_Pole_Mid_L 91 8211\n",
    "Temporal_Pole_Mid_R 92 8212\n",
    "Temporal_Inf_L 93 8301\n",
    "Temporal_Inf_R 94 8302\n",
    "Cerebelum_Crus1_L 95 9001\n",
    "Cerebelum_Crus1_R 96 9002\n",
    "Cerebelum_Crus2_L 97 9011\n",
    "Cerebelum_Crus2_R 98 9012\n",
    "Cerebelum_3_L 99 9021\n",
    "Cerebelum_3_R 100 9022\n",
    "Cerebelum_4_5_L 101 9031\n",
    "Cerebelum_4_5_R 102 9032\n",
    "Cerebelum_6_L 103 9041\n",
    "Cerebelum_6_R 104 9042\n",
    "Cerebelum_7b_L 105 9051\n",
    "Cerebelum_7b_R 106 9052\n",
    "Cerebelum_8_L 107 9061\n",
    "Cerebelum_8_R 108 9062\n",
    "Cerebelum_9_L 109 9071\n",
    "Cerebelum_9_R 110 9072\n",
    "Cerebelum_10_L 111 9081\n",
    "Cerebelum_10_R 112 9082\n",
    "Vermis_1_2 113 9100\n",
    "Vermis_3 114 9110\n",
    "Vermis_4_5 115 9120\n",
    "Vermis_6 116 9130\n",
    "Vermis_7 117 9140\n",
    "Vermis_8 118 9150\n",
    "Vermis_9 119 9160\n",
    "Vermis_10 120 9170\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parse the data into a dictionary\n",
    "regions_dict = {}\n",
    "for line in regions_data.strip().split(\"\\n\"):\n",
    "    parts = line.split()\n",
    "    region_name = parts[0]\n",
    "    atlas_index = int(parts[2])\n",
    "    regions_dict[region_name] = atlas_index\n",
    "\n",
    "# Function to create a binary mask for the given region indices\n",
    "def create_region_mask(atlas_img, region_indices):\n",
    "    mask = np.zeros(atlas_img.shape, dtype=bool)\n",
    "    for index in region_indices:\n",
    "        region_mask = math_img(f'img == {index}', img=atlas_img)\n",
    "        mask |= region_mask.get_fdata().astype(bool)\n",
    "    return new_img_like(atlas_img, mask)\n",
    "\n",
    "# Plot regions for each community\n",
    "n_communities = len(community_clustering_with_names)\n",
    "fig, axes = plt.subplots(2, (n_communities + 1) // 2, figsize=(20, 10))\n",
    "\n",
    "if n_communities == 1:\n",
    "    axes = np.array([axes])  # Ensure axes is iterable\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Assuming aal_atlas is predefined as the atlas image\n",
    "for ax, (community_number, region_names) in zip(axes, enumerate(community_clustering_with_names)):\n",
    "\n",
    "    region_indices = [regions_dict[name] for name in region_names if \"Unknown\" not in name]\n",
    "    region_mask = create_region_mask(aal_atlas, region_indices)\n",
    "    plotting.plot_roi(region_mask, title=f\"Community {community_number}\", axes=ax, display_mode='ortho', draw_cross=False,cmap=mpl.cm.viridis)\n",
    "\n",
    "# Hide any unused subplots\n",
    "for ax in axes[len(community_clustering_with_names):]:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Define the variables\n",
    "date_time = '2024-06-03_21-50-02 bl'\n",
    "z_scoring = 'Z_scoring'\n",
    "percentile = 10\n",
    "class_pair1 = ['CN', 'SMC']\n",
    "class_pair2 = ['MCI', 'EMCI', 'LMCI']\n",
    "# Construct class pair strings with single quotes\n",
    "class_pair1_str = ', '.join([f\"'{c}'\" for c in class_pair1])\n",
    "class_pair2_str = ', '.join([f\"'{c}'\" for c in class_pair2])\n",
    "\n",
    "# Construct the file path\n",
    "\n",
    "file_path = f\"/home/hang/GitHub/BrainGNN_Pytorch/results/{date_time}/{z_scoring}/{percentile}/[{class_pair1_str}]_vs_{class_pair2}/results/score1s.json\"\n",
    "\n",
    "# Load the JSON data from the uploaded file\n",
    "with open(file_path, 'r') as f:\n",
    "    scores = json.load(f)\n",
    "\n",
    "# Function to recursively flatten lists and filter numeric values\n",
    "def flatten_and_filter(lst):\n",
    "    flat_list = []\n",
    "    for item in lst:\n",
    "        if isinstance(item, (list, tuple)):\n",
    "            flat_list.extend(flatten_and_filter(item))\n",
    "        elif isinstance(item, (int, float)):\n",
    "            flat_list.append(item)\n",
    "    return flat_list\n",
    "\n",
    "values = []\n",
    "for key in scores.keys():\n",
    "    values.extend(flatten_and_filter(scores[key]))\n",
    "# Remove the last 60 digits from the values list\n",
    "\n",
    "# Check if the values list is empty before proceeding\n",
    "if len(values) == 0:\n",
    "    top_indices_list = \"No valid numeric data found.\"\n",
    "else:\n",
    "    # Ensure that the number of values is a multiple of 120\n",
    "    if len(values) % 120 != 0:\n",
    "        raise ValueError(\"The number of values is not a multiple of 120 after removing the last 60 digits. Please check the input data.\")\n",
    "\n",
    "    num_subjects = len(values) // 120\n",
    "    subject_scores = []\n",
    "\n",
    "    # Iterate over the values in chunks of 120\n",
    "    for i in range(num_subjects):\n",
    "        chunk = values[i*120:(i+1)*120]\n",
    "        subject_scores.append(chunk)\n",
    "    print(len(subject_scores))\n",
    "    # Convert the list of subject scores to a NumPy array\n",
    "    subject_scores = np.array(subject_scores)\n",
    "    \n",
    "    # Calculate the average score for each ROI across all subjects\n",
    "    average_scores = np.mean(subject_scores, axis=0)\n",
    "    \n",
    "    # Determine the threshold for the top 25% of the average scores\n",
    "    threshold = np.percentile(average_scores, 75)\n",
    "    \n",
    "    # Find the indices of the ROIs that have average scores above the threshold\n",
    "    top_indices = np.where(average_scores >= threshold)[0]\n",
    "    \n",
    "    # Convert indices to list for easy readability\n",
    "    top_indices_list = top_indices.tolist()\n",
    "\n",
    "print(f\"Extracted average scores (sample): {average_scores[:20]}\")  # Print first 20 average scores for inspection\n",
    "print(f\"Total number of ROIs: {len(average_scores)}\")\n",
    "print(f\"Top 25% ROI indices: {top_indices_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#perm1s_0 = np.load('results/2024-06-10_09-23-12/perturbation/20/CN_vs_MCI/results/perm1_class_0.npy') \n",
    "perm1s_1 = np.load('results/2024-06-10_11-03-36/perturbation/5/CN_vs_MCI/results/perm1_class_1.npy')\n",
    "print(perm1s_1)\n",
    "#perm1s = np.concatenate([perm1s_0,perm1s_1])\n",
    "#print(perm1s.shape)\n",
    "#perm2s_0 = np.load('results/2024-06-10_09-23-12/perturbation/20/CN_vs_MCI/results/perm2_class_0.npy') \n",
    "perm2s_1 = np.load('results/2024-06-10_11-03-36/perturbation/5/CN_vs_MCI/results/perm2_class_1.npy')\n",
    "#perm2s = np.concatenate([perm2s_0,perm2s_1])\n",
    "print(perm2s_1)\n",
    "# Flatten the indices if they were saved as lists of lists\n",
    "perm1s = perm1s_1.flatten()\n",
    "perm2s = perm2s_1.flatten()\n",
    "# print(perm2s.shape)\n",
    "# Convert the indices to match the original graph nodes\n",
    "final_node_indices = perm1s[perm2s]\n",
    "print(len(final_node_indices))\n",
    "chunk_size = 30\n",
    "subject_perms = []\n",
    "print(len(final_node_indices)/30)\n",
    "for i in range(int(len(final_node_indices)/chunk_size)):\n",
    "\n",
    "    subject_perms.append(final_node_indices[i*chunk_size:(i+1)*chunk_size]%120)\n",
    "subject_perms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn import plotting, image\n",
    "from nilearn.image import math_img, resample_to_img,new_img_like\n",
    "from collections import defaultdict\n",
    "\n",
    "regions_dict = {}\n",
    "value_to_region = {}\n",
    "\n",
    "# Populate dictionaries\n",
    "for line in regions_data.strip().split('\\n'):\n",
    "    parts = line.split()\n",
    "    region_name = parts[0]\n",
    "    second_col_value = int(parts[1])\n",
    "    third_col_value = int(parts[2])\n",
    "    regions_dict[second_col_value] = region_name\n",
    "    value_to_region[third_col_value] = region_name\n",
    "\n",
    "# Define the path to the AAL2 atlas\n",
    "path_to_aal2 = '/home/hang/dsi-studio/atlas/ICBM152_adult/AAL2.nii.gz'\n",
    "aal_atlas = image.load_img(path_to_aal2)\n",
    "\n",
    "def generate_plots(base_path, percentile, group_pair):\n",
    "    # Define paths to the data files\n",
    "    perm1_path_0 = os.path.join(base_path, f'{percentile}', f'{group_pair}', 'results', 'perm1_class_0.npy')\n",
    "    perm1_path_1 = os.path.join(base_path, f'{percentile}', f'{group_pair}', 'results', 'perm1_class_1.npy')\n",
    "    perm2_path_0 = os.path.join(base_path, f'{percentile}', f'{group_pair}', 'results', 'perm2_class_0.npy')\n",
    "    perm2_path_1 = os.path.join(base_path, f'{percentile}', f'{group_pair}', 'results', 'perm2_class_1.npy')\n",
    "\n",
    "    # Load the data\n",
    "    perm1s_0 = np.load(perm1_path_0)\n",
    "    perm1s_1 = np.load(perm1_path_1)\n",
    "\n",
    "    perm2s_0 = np.load(perm2_path_0)\n",
    "    perm2s_1 = np.load(perm2_path_1)\n",
    "\n",
    "\n",
    "    # Process class 0 data\n",
    "    perm1s_0 = perm1s_0.flatten()\n",
    "    perm2s_0 = perm2s_0.flatten()\n",
    "    final_node_indices_0 = perm1s_0[perm2s_0]\n",
    "    print(final_node_indices_0.shape)\n",
    "\n",
    "\n",
    "    # Process class 1 data\n",
    "    perm1s_1 = perm1s_1.flatten()\n",
    "    perm2s_1 = perm2s_1.flatten()\n",
    "    final_node_indices_1 = perm1s_1[perm2s_1]\n",
    "    print(final_node_indices_1.shape)\n",
    "    # Split the indices by subject (assuming each subject has 30 nodes originally)\n",
    "    chunk_size = 30  # Number of nodes per subject before pooling\n",
    "    subject_perms_0 = []\n",
    "    subject_perms_1 = []\n",
    "\n",
    "    for i in range(int(len(final_node_indices_0) / chunk_size)):\n",
    "        subject_perms_0.append(final_node_indices_0[i * chunk_size:(i + 1) * chunk_size] % 120)\n",
    "\n",
    "    for i in range(int(len(final_node_indices_1) / chunk_size)):\n",
    "        subject_perms_1.append(final_node_indices_1[i * chunk_size:(i + 1) * chunk_size] % 120)\n",
    "\n",
    "    # Function to summarize and visualize unique regions for a given class\n",
    "    def summarize_class_regions(subject_perms, class_label):\n",
    "        unique_regions = set()\n",
    "\n",
    "        for perms in subject_perms:\n",
    "            final_regions = [regions_dict.get(idx, 'Unknown') for idx in perms]\n",
    "            unique_regions.update(final_regions)\n",
    "\n",
    "        unique_region_indices = [key for key, value in value_to_region.items() if value in unique_regions]\n",
    "\n",
    "        if unique_region_indices:\n",
    "            # Create a mask image for the selected regions\n",
    "            region_mask = np.isin(aal_atlas.get_fdata(), unique_region_indices)\n",
    "            mask_img = image.new_img_like(aal_atlas, region_mask.astype(np.int8))\n",
    "\n",
    "            # Save the plot\n",
    "            plot_path = os.path.join(base_path, f'{percentile}', f'{group_pair}', 'plots', f'class_{class_label}_unique_regions.png')\n",
    "            os.makedirs(os.path.dirname(plot_path), exist_ok=True)\n",
    "            \n",
    "            # Plot the regions on the brain atlas\n",
    "            display = plotting.plot_anat()\n",
    "            plotting.plot_roi(mask_img, display_mode='ortho', draw_cross=True, title=f'Unique Retained Regions for Class {class_label}: {group_pair.split(\"_vs_\")[class_label]}', output_file=plot_path)\n",
    "\n",
    "            # Ensure the figure is rendered\n",
    "            # plotting.show()\n",
    "            plt.close()\n",
    "\n",
    "    # Summarize and visualize unique regions for class 0\n",
    "    summarize_class_regions(subject_perms_0, class_label=0)\n",
    "\n",
    "    # Summarize and visualize unique regions for class 1\n",
    "    summarize_class_regions(subject_perms_1, class_label=1)\n",
    "    print(f'Class 0 subjects: {len(subject_perms_0)}, Class 1 subjects: {len(subject_perms_1)}')\n",
    "\n",
    "# Base path for your data\n",
    "base_path = 'results/2024-06-12_18-08-37 perturbation fp/perturbation'\n",
    "\n",
    "# Iterate through each combination of percentile and group pair\n",
    "percentiles = [5, 10, 15, 20, 25]\n",
    "group_pairs = ['MCI_vs_Dementia', 'CN_vs_Dementia', 'CN_vs_MCI', 'CN_vs_CN']\n",
    "\n",
    "for percentile in percentiles:\n",
    "    print(f'Percentile: {percentile}')\n",
    "    for group_pair in group_pairs:\n",
    "        print(f'Group pair: {group_pair}')\n",
    "        generate_plots(base_path, percentile, group_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn import plotting, image\n",
    "from nilearn.image import math_img, resample_to_img,new_img_like\n",
    "from collections import defaultdict\n",
    "regions_dict = {}\n",
    "value_to_region = {}\n",
    "\n",
    "# Populate dictionaries\n",
    "for line in regions_data.strip().split('\\n'):\n",
    "    parts = line.split()\n",
    "    region_name = parts[0]\n",
    "    second_col_value = int(parts[1])\n",
    "    third_col_value = int(parts[2])\n",
    "    regions_dict[second_col_value] = region_name\n",
    "    value_to_region[third_col_value] = region_name\n",
    "def generate_plots(base_path, method, percentile, group_pair):\n",
    "    # Convert group_pair to a string representation with single quotes around each element\n",
    "    def format_group(group):\n",
    "        if isinstance(group, list):\n",
    "            return ', '.join([f\"'{elem}'\" for elem in group])\n",
    "        else:\n",
    "            return f\"{group}\"\n",
    "    \n",
    "    # Format group_pair string\n",
    "    if isinstance(group_pair[1], list):\n",
    "        group_pair_str = f\"[{format_group(group_pair[0])}]_vs_[{format_group(group_pair[1])}]\"\n",
    "    else:\n",
    "        group_pair_str = f\"[{format_group(group_pair[0])}]_vs_{format_group(group_pair[1])}\"\n",
    "    \n",
    "    # Define paths to the data files\n",
    "    perm1_path_0 = os.path.join(base_path, method, f'{percentile}', f\"{group_pair_str}\", 'results', 'perm1_class_0.npy')\n",
    "    perm1_path_1 = os.path.join(base_path, method, f'{percentile}', f\"{group_pair_str}\", 'results', 'perm1_class_1.npy')\n",
    "    perm2_path_0 = os.path.join(base_path, method, f'{percentile}', f\"{group_pair_str}\", 'results', 'perm2_class_0.npy')\n",
    "    perm2_path_1 = os.path.join(base_path, method, f'{percentile}', f\"{group_pair_str}\", 'results', 'perm2_class_1.npy')\n",
    "\n",
    "    # Load the data\n",
    "    perm1s_0 = np.load(perm1_path_0)\n",
    "    perm1s_1 = np.load(perm1_path_1)\n",
    "\n",
    "    perm2s_0 = np.load(perm2_path_0)\n",
    "    perm2s_1 = np.load(perm2_path_1)\n",
    "\n",
    "\n",
    "    # Process class 0 data\n",
    "    perm1s_0 = perm1s_0.flatten()\n",
    "    perm2s_0 = perm2s_0.flatten()\n",
    "    final_node_indices_0 = perm1s_0[perm2s_0]\n",
    "\n",
    "    # Process class 1 data\n",
    "    perm1s_1 = perm1s_1.flatten()\n",
    "    perm2s_1 = perm2s_1.flatten()\n",
    "    final_node_indices_1 = perm1s_1[perm2s_1]\n",
    "\n",
    "    # Split the indices by subject (assuming each subject has 30 nodes originally)\n",
    "    chunk_size = 30  # Number of nodes per subject before pooling\n",
    "    subject_perms_0 = []\n",
    "    subject_perms_1 = []\n",
    "\n",
    "    for i in range(int(len(final_node_indices_0) / chunk_size)):\n",
    "        subject_perms_0.append(final_node_indices_0[i * chunk_size:(i + 1) * chunk_size] % 120)\n",
    "\n",
    "    for i in range(int(len(final_node_indices_1) / chunk_size)):\n",
    "        subject_perms_1.append(final_node_indices_1[i * chunk_size:(i + 1) * chunk_size] % 120)\n",
    "\n",
    "    # Function to summarize and visualize unique regions for a given class\n",
    "    def summarize_class_regions(subject_perms, class_label):\n",
    "        unique_regions = set()\n",
    "\n",
    "        for perms in subject_perms:\n",
    "            final_regions = [regions_dict.get(idx, 'Unknown') for idx in perms]\n",
    "            unique_regions.update(final_regions)\n",
    "\n",
    "        unique_region_indices = [key for key, value in value_to_region.items() if value in unique_regions]\n",
    "\n",
    "        if unique_region_indices:\n",
    "            # Create a mask image for the selected regions\n",
    "            region_mask = np.isin(aal_atlas.get_fdata(), unique_region_indices)\n",
    "            mask_img = image.new_img_like(aal_atlas, region_mask.astype(np.int8))\n",
    "\n",
    "            # Save the plot\n",
    "            plot_path = os.path.join(base_path, method, f'{percentile}', f\"{group_pair_str}\", 'plots', f'class_{class_label}_unique_regions.png')\n",
    "            os.makedirs(os.path.dirname(plot_path), exist_ok=True)\n",
    "            \n",
    "            # Plot the regions on the brain atlas\n",
    "            display = plotting.plot_anat()\n",
    "            plotting.plot_roi(mask_img, display_mode='ortho', draw_cross=True, title=f'Unique Retained Regions for Class {class_label}: {group_pair[class_label]}', output_file=plot_path)\n",
    "\n",
    "            # Ensure the figure is rendered\n",
    "            #plotting.show()\n",
    "            #plt.close()\n",
    "\n",
    " \n",
    "    summarize_class_regions(subject_perms_0, class_label=0)\n",
    "    summarize_class_regions(subject_perms_1, class_label=1)\n",
    "    print(subject_perms_0,subject_perms_1)\n",
    "\n",
    "# Base path for your data\n",
    "base_path = 'results/2024-06-12_20-47-08 bl'\n",
    "\n",
    "# Iterate through each combination of method, percentile, and group pair\n",
    "methods = ['K_correlation', 'K_JS_Divergence', 'ScaledMahalanobisDistanceMatrix', 'Z_scoring']  # Add more methods if needed\n",
    "percentiles = [5, 10, 15, 20, 25]  # Add more percentiles if needed\n",
    "class_pairs = [\n",
    "    (['CN', 'SMC'], ['MCI', 'EMCI', 'LMCI']),\n",
    "    (['CN', 'SMC'], 'Dementia'),\n",
    "    (['CN', 'SMC'], ['CN', 'SMC']),  # Assuming 'CN ab+' is represented like this in the 'DX_bl' column\n",
    "    (['MCI', 'EMCI', 'LMCI'], 'Dementia')\n",
    "]\n",
    "\n",
    "for method in methods:\n",
    "    for percentile in percentiles:\n",
    "        for group_pair in class_pairs:\n",
    "            generate_plots(base_path, method, percentile, group_pair)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
